<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
<title>Help Wanted</title>
<description>Help Wanted Issues</description>
<link>https://lbonanomi.github.io/rss/feed.xml</link>
<item>
	<title>Add Carthage compatibility badge to the README</title>
	<link>https://github.com/github/Archimedes/issues/38</link>
	<description><![CDATA[Using [these instructions](https://github.com/Carthage/Carthage/blob/7a0153cc164e301c46527f6e20c886728a0dc218/README.md#declare-your-compatibility).<br/>" ]]></description>
</item>

<item>
	<title>Test that license texts match SPDX plain license texts</title>
	<link>https://github.com/github/choosealicense.com/issues/636</link>
	<description><![CDATA[We should have a test that each license text in ` ]]></description>
</item>

<item>
	<title>Annotating license texts with license rules</title>
	<link>https://github.com/github/choosealicense.com/issues/441</link>
	<description><![CDATA[[Comment/question today](https://github.com/github/choosealicense.com/pull/320#issuecomment-230746990) about whether EUPL-1.1 is accurately described reminded me to file this enhancement idea.<br/><br/>For each license, license rules could be annotated with ranges of text in the license pertinent to the rule. Highlighting of ranges could be turned on/off on individual license pages by selecting in the license rules (permissions/conditions/limitations) table. Very crude mockup taking a very simple case (the one condition of MIT).<br/><br/>![mit-highlight-condition](https://cloud.githubusercontent.com/assets/40415/16633043/25735510-437c-11e6-84f8-1e504d48f345.png)<br/><br/>Obviously this is not a big help for MIT, but for longer licenses, it can be tricky to figure out what bits of the license are pertinent for a particular rule, at least if you only want to read once, which is more already than I suspect most people do.<br/><br/>Such annotations  ]]></description>
</item>

<item>
	<title>Add Free Art License</title>
	<link>https://github.com/github/choosealicense.com/issues/314</link>
	<description><![CDATA[[Free Art License 1.3](http://artlibre.org/licence/lal/en/)<br/>" ]]></description>
</item>

<item>
	<title>I18N</title>
	<link>https://github.com/github/choosealicense.com/issues/68</link>
	<description><![CDATA[Would love to see about baking in I18N support to choosealicense.com proper. See #67 and #62<br/><br/>We already have the bulk of the strings in a single file (` ]]></description>
</item>

<item>
	<title>TODO: Configure caching for fast building on travisci</title>
	<link>https://github.com/github/government.github.com/issues/750</link>
	<description><![CDATA[Description and details here: https://github.com/gjtorikian/html-proofer#configuring-caching and https://github.com/gjtorikian/html-proofer#caching-with-travis" ]]></description>
</item>

<item>
	<title>Alphabetize, other chores should run monthly, open new PRs automatically</title>
	<link>https://github.com/github/government.github.com/issues/601</link>
	<description><![CDATA[Currently, the alphabetize script (https://github.com/github/government.github.com/blob/gh-pages/script/alphabetize)  is run manually to clean up the ordering of Organizations in the various data files. (Example: https://github.com/github/government.github.com/pull/582). A couple problems with this:<br/><br/>1. Why do work that a robot ðŸ¤– can do?<br/>2. Since this repo is widely maintained, it's impossible to guarantee that these changes won't create pretty annoying conflicts for other PRs. <br/><br/>Getting these to a near automated fashion would be really cool.<br/><br/>I'd held off merging a bunch of [open PRs](https://github.com/github/government.github.com/pulls?utf8=%E2%9C%93&amp;q=is%3Apr%20is%3Aopen%20updated%3A%3E2017-07-01) in hopes that I'd get time to work on a solution for this, but alas I have not. So, I figure I'll crowd source this to see if anyone has any ideas or fancy the execution.<br/><br/>## Note<br/>I'd love to use [probot](https://probot.github.io) as the framework for these operations (it's what it was made for), but it's currently a node app and is expecting j/s scripts. Since I try to do as little with YAML as possible ðŸ˜‰ , this task was never exciting enough to get my attention for very long, and why it floundered. It should be pretty easy as `js-yaml` and basic JS functions should map pretty cleanly.<br/><br/>By opening this issue, this will be a reminder to me to eventually get to it too, so no pressure." ]]></description>
</item>

<item>
	<title>XML report for CI</title>
	<link>https://github.com/github/licensed/issues/52</link>
	<description><![CDATA[Hi,<br/><br/>I'm integrating licensed for a poc in our Jenkins pipeline. It could be great to get a report of all licenses checks in an XML formatted file; so we can process it using Jenkins plugins. For now, I have to analyse the `XXX dependencies checked, XXX warnings found.` string formatted output of `licensed status` command.<br/><br/>We can consider **licensed results** as **tests results**.<br/>* If all licenses check passed; then the overall test is **passed**.<br/>* If one license is found as unknown, or not matching any of allowed, ignored or reviewed configs; then the check/test **failed**.<br/><br/>Standards test output formats such as junit, nunit, mstest, google-test, etc. would be great cos already known by many CI tools. Junit is probably the most used one.<br/><br/>Organizing tests in \"groups\" matching the package type (npm, pip, go, etc.) and license type (mit, gpl...) would also allows to \"count\" the type of licenses found... providing some kind of statistics ^<br/><br/>Example of output in Jenkins test plugin results, processing the XML file could be:<br/>```<br/>Package                  Fail Skip Pass Total<br/>- total                     0    0   69    69<br/>- npm                       0    0   53    53<br/>  - mit                     0    0   45    45<br/>    - package1              0    0    1     1<br/>    - package 2             ...<br/>    - ...<br/>  - apache-2.0                              3<br/>    - package46<br/>    - ...<br/>  - bsd-3-clause                            1 <br/>    - package49<br/>  - isc                                     1<br/>    - package50<br/>  - unknown                                 3<br/>    - package51             1    0    0     1<br/>    - ...<br/>- go                                       16<br/>  - mit                                    14<br/>    - ...<br/>  - isc                                     1<br/>    - ...<br/>  - unknown                                 1<br/>    - packagexx             1    0    0     1<br/>    - ...<br/>```<br/>I did not fill the array; but you've got the point ;-)<br/><br/>Regards,<br/><br/>Chris" ]]></description>
</item>

<item>
	<title>Add a yarn dependency source</title>
	<link>https://github.com/github/licensed/issues/31</link>
	<description><![CDATA[As found in https://github.com/github/licensed/issues/30#issuecomment-386129385<br/><br/>> The errors appear to be because my package.json file is actually intended for yarn, and uses some syntax that is not npm-compatible<br/><br/>[Yarn's](https://yarnpkg.com/) `package.json` files attempt to be compatible with NPM `package.json` files but can contain differences that cause the NPM dependency source to fail.<br/><br/>It looks like an indicator that yarn should be used and that npm shouldn't be used is the presence of a `yarn.lock` file." ]]></description>
</item>

<item>
	<title>Invalid event parameters when setting a reminder</title>
	<link>https://github.com/github/opensourcefriday/issues/105</link>
	<description><![CDATA[After signing up and clicking on Add to Calendar -> Google Calendar (under Set a reminder), getting the following error - <br/>![screen shot 2017-06-27 at 10 57 39 pm](https://user-images.githubusercontent.com/6823117/27601277-64e039ce-5b8c-11e7-91d0-6fc0170391ad.png)<br/>" ]]></description>
</item>

<item>
	<title>delete-empty-repos.sh - Handle Pagination</title>
	<link>https://github.com/github/platform-samples/issues/190</link>
	<description><![CDATA[[delete-empty-repos.sh](https://github.com/github/platform-samples/blob/master/api/bash/delete-empty-repos.sh) currently works with default pagination of only 30 repositories.<br/><br/>Need to handle pagination in case of more than 30 repositories are within the organization.<br/><br/>[Relevant Doc](https://developer.github.com/v3/guides/traversing-with-pagination/)" ]]></description>
</item>

<item>
	<title>Finish migrating to `pathtype` library.</title>
	<link>https://github.com/github/semantic/issues/288</link>
	<description><![CDATA[The migration to `pathtype` has been overall a pleasant oneâ€”it makes functions much more indicative of their purpose, and itâ€™s caught some bugs (though not serious ones). Right now weâ€™re an uneasy hybrid of `pathtype` solutions and `FilePath`; we should move off of the latter completely. This involves overhauling `Semantic.CLI` to use `pathtype`; the [documentation](http://hackage.haskell.org/package/pathtype-0.8.1) provides a recipe to make `optparse-applicative` parsers do the right thing (respecting the path semantics; i.e., if we tell a parser to expect an absolute path, the parser will fail unless said path is actually absolute.)" ]]></description>
</item>

<item>
	<title>Clojure(Script) support</title>
	<link>https://github.com/github/semantic/issues/217</link>
	<description><![CDATA[Any possibility of adding Clojure/ClojureScript support?" ]]></description>
</item>

<item>
	<title>Don't connect to kext when invoked with CLI args</title>
	<link>https://github.com/github/SoftU2F/issues/39</link>
	<description><![CDATA[We try to connect to the kext when the app starts ([code](https://github.com/github/SoftU2F/blob/45825a5bd6e6bad7ae9bd681c8584cbcb6e7fb7b/SoftU2FTool/U2FHID.swift#L24)). This also happens when the app is launched from the command line (Eg. for deleting/listing registrations). If the app is already running in the background we'll get an error because the kext only allows one connection. This error is surfaced to the user, which is confusing. We should not connect to the kext unless we need to." ]]></description>
</item>

<item>
	<title>Add Draft PR support</title>
	<link>https://github.com/github/VisualStudio/issues/2329</link>
	<description><![CDATA[**Is your feature request related to a problem? Please describe.**<br/>I wouldn't say it's a problem, but it would be nice to add support to create draft PRs inside Visual Studio.<br/><br/>**Describe the solution you'd like**<br/>Draft PRs will allow users to create PRs earlier in the development workflow and also provide more parity with dotcom.<br/><br/>This work would include being able to:<br/>- create draft PRs<br/>- view draft PRs<br/>- filter by a status of draft" ]]></description>
</item>

<item>
	<title>elastic: write log entries to logs indices using a correct mapping for the @timestamp field</title>
	<link>https://github.com/grafana/fake-data-gen/issues/8</link>
	<description><![CDATA[Currently data are written to logs indices, but I cannot use the indices as datasource in grafana because I got error that @timestamp is not a valie time field." ]]></description>
</item>

<item>
	<title>Grafana won't render OpenTSDB timeseries starting with a NaN</title>
	<link>https://github.com/grafana/grafana/issues/19770</link>
	<description><![CDATA[**What happened**:<br/><br/>Chart line failed to render when a NaN was found at the start of the response from OpenTSDB. Chart renders fine when there are NaNs in the data, but not at the start.<br/><br/>**What you expected to happen**:<br/><br/>No difference between responses starting and just containing NaN.<br/><br/>**How to reproduce it (as minimally and precisely as possible)**:<br/><br/>Construct a query which returns NaN at the start of the returned data. See attachments for example query inspector captures.<br/>[startsData.json.txt](https://github.com/grafana/grafana/files/3718227/startsData.json.txt)<br/>[startsNaN.json.txt](https://github.com/grafana/grafana/files/3718229/startsNaN.json.txt)<br/><br/><br/><br/>**Anything else we need to know?**:<br/>I don't think so.<br/><br/>**Environment**:<br/>- Grafana version: 6.3.2<br/>- Data source type &amp; version: OpenTSDB - awaiting version<br/>- OS Grafana is installed on:<br/>  Linux - awaiting version<br/>- User OS &amp; Browser: <br/>  Chrome 75.0.3770.100 (Official Build) (64-bit) <br/>  Windows 10 OS Version 1803 (Build 17134.984)<br/>- Grafana plugins:<br/>- Others:<br/>" ]]></description>
</item>

<item>
	<title>Self signed certificates</title>
	<link>https://github.com/grafana/grafana-image-renderer/issues/33</link>
	<description><![CDATA[I tested the render plugin against a Grafana instance with self signed certificate. I got the following error:<br/>Error: net::ERR ]]></description>
</item>

<item>
	<title>upgrade to schemaVersion 16</title>
	<link>https://github.com/grafana/grafonnet-lib/issues/66</link>
	<description><![CDATA[Forgive my ignorance, but is this on the roadmap?  Is it worth doing today, or are we waiting for a subsequent/stable schema version to upgrade to?  I can potentially help, though I'd need a little bit of guidance.<br/><br/>Looking at the [dashboard migration logic](https://github.com/grafana/grafana/blob/master/public/app/features/dashboard/dashboard ]]></description>
</item>

<item>
	<title>Template current value does not work with multivalue template variables</title>
	<link>https://github.com/grafana/grafonnet-lib/issues/65</link>
	<description><![CDATA[When trying to pass in multiple values for current value of template variable it does not generate json understood by grafana." ]]></description>
</item>

<item>
	<title>docs: Labels recommendations</title>
	<link>https://github.com/grafana/loki/issues/1117</link>
	<description><![CDATA[I was searching through our recommendations for labels and couldn't find anything.<br/><br/>I think we should have in our user documentation some explanation about what are bad and good labels with some nice example.<br/><br/>Somwhere here https://github.com/grafana/loki/blob/master/docs/clients/README.md<br/><br/>We should also explain how to have the same labels in Prometheus and Why ? (switching from metrics to logs).<br/><br/>" ]]></description>
</item>

<item>
	<title>Different packaging for release binaries</title>
	<link>https://github.com/grafana/loki/issues/1113</link>
	<description><![CDATA[We deploy `promtail` on all our infra VMs as native binaries. Unfortunately the choice of gunzipping the binary file is a bit incovenient for us for two reasons:<br/><br/>1. We deploy with Saltstack that natively (through archive.extract) is unable to open .gz files (it can open .tar.gz though)<br/>2. On Windows there's no native tool that can uncompress the .gz file and thus would require to install gzip first (or similar archive manager)<br/><br/>A simple solution could be to compress the resulting binary in `.zip` format which is much more supported.<br/><br/>Alternatively the uncompressed binary would work too.<br/><br/>How does the community feel about this?<br/>Thanks!<br/>" ]]></description>
</item>

<item>
	<title>Color of diff changes when scrolling up and down</title>
	<link>https://github.com/grafana/tanka/issues/82</link>
	<description><![CDATA[Example: https://www.youtube.com/watch?v=1UKlgCK2EeM<br/>" ]]></description>
</item>

<item>
	<title>Make tanka available as kubectl plugin</title>
	<link>https://github.com/grafana/tanka/issues/45</link>
	<description><![CDATA[Looking at this project, I think it should be possible to make this interface with the kubectl plugins and distribute via krew.<br/>https://github.com/kubernetes-sigs/krew<br/><br/>Let me know what you think! " ]]></description>
</item>

<item>
	<title>tab completion shows too much of the path.</title>
	<link>https://github.com/grafana/tanka/issues/29</link>
	<description><![CDATA[If I do `cd environments/` then press tab, I will see listed the directories inside `environments`.<br/><br/>If I do the same with `tk diff environments`, I will see `environments/default/blah`. It would be more helpful if it stripped off the `environments` portion, as I have already committed to that part of the path.<br/><br/>Also, it currently lists *all* of the paths that have a `main.jsonnet`. This is neat, but gives too many options. I would expect a sequence such as:<br/><br/>```<br/>$ tk diff env<TAB><br/>$ tk diff environments/<br/>$ tk diff environments/<TAB><br/>default hosted-grafana cortex loki cassandra blah<br/>$ tk diff environments/cor<TAB><br/>$ tk diff environments/cortex/<br/>$ tk diff environments/cortex/<TAB><br/>eu-west2.dev eu-west2.prod ops-tools1-us-east4.cortex blah<br/>$ tk diff environments/cortex/ops<TAB><br/>$ tk diff environments/cortex/ops-tools1-us-east4.cortex<br/>```<br/>Here it has stopped completing, i.e. didn't put a `/` at the end of the dir, because there is a `main.jsonnet` file in that directory.<br/><br/>This would allow me to navigate swiftly to where I want to be without overfilling my screen. <br/>" ]]></description>
</item>

<item>
	<title>Deduplicate the command-line parameters</title>
	<link>https://github.com/awslabs/amazon-pollexy/issues/2</link>
	<description><![CDATA[Several of the click options/arguments are shared across difference commands . . . need to de-dupe this code as much as possible." ]]></description>
</item>

<item>
	<title>Add configuration of the config Aggregator as part of the deployment</title>
	<link>https://github.com/awslabs/aws-config-engine-for-compliance-as-code/issues/31</link>
	<description><![CDATA[" ]]></description>
</item>

<item>
	<title>New Method in ConfigEvent</title>
	<link>https://github.com/awslabs/aws-config-rules/issues/143</link>
	<description><![CDATA[The configEvent class from aws-lambda-java-events has been updated one of the methods and needs to be updated in the Source code also. <br/> isEventLeftScope -> getEventLeftScope " ]]></description>
</item>

<item>
	<title>Add support for multiple deployoment OU in nested structure</title>
	<link>https://github.com/awslabs/aws-deployment-framework/issues/130</link>
	<description><![CDATA[We're looking to implement ADF for our organisation, and at the moment it works pretty well for just our team. In future, if all goes smoothly with our spike, we'll likely be looking to roll this out to multiple teams in the larger group, we wouldn't want to share a deployment account since we need that separation (and there would be a lot of pipelines in there getting cluttered). However we do still share an Organization (billing reasons, Security, etc), and we think it would be great if ADF could support multiple deployment accounts in a similar structure as listed below:<br/><br/>```<br/>+ root org<br/>     + team1<br/>          + deployment<br/>               - tooling-account (isolated to only allow deployment to units within team1)<br/>          + production<br/>               - team1-prod<br/>          + staging<br/>               - team1-staging<br/>     + team2<br/>          + deployment<br/>               - tooling-account (isolated to only allow deployment to units within team2)<br/>          + production<br/>               - team2-prod<br/>          + staging<br/>               - team2-staging<br/>     + team3<br/>          + deployment<br/>               - tooling-account (isolated to only allow deployment to units within team3)<br/>          + production<br/>               - team3-prod<br/>          + staging<br/>               - team3-staging<br/>```<br/><br/>Is this the sort of feature that could be implemented at some point? Its my understanding that currently the tool only supports one deployment account due to the system-parameters upon initialisation.<br/><br/>Another structure that could work, but we aren't sure if its possible/how to implement:<br/><br/>```<br/>+ root org<br/>    + deployment<br/>         - team1-tooling<br/>         - team2-tooling<br/>         - team3-tooling<br/>     + team1<br/>          + production<br/>               - team1-prod<br/>          + staging<br/>               - team1-staging<br/>     + team2<br/>          + production<br/>               - team2-prod<br/>          + staging<br/>               - team2-staging<br/>     + team3<br/>          + production<br/>               - team3-prod<br/>          + staging<br/>               - team3-staging<br/>```" ]]></description>
</item>

<item>
	<title>Functions: Cannot specify 'Pinned' value</title>
	<link>https://github.com/awslabs/aws-greengrass-group-setup/issues/9</link>
	<description><![CDATA[As the API is currently exposed, lambda functions referenced with gg ]]></description>
</item>

<item>
	<title>Check for valid regions in GroupCommands</title>
	<link>https://github.com/awslabs/aws-greengrass-group-setup/issues/2</link>
	<description><![CDATA[The `create`, `clean ]]></description>
</item>

<item>
	<title>Feature Request: Auto-detect policy document fragment format</title>
	<link>https://github.com/awslabs/aws-iam-generator/issues/17</link>
	<description><![CDATA[As a user, I should be able to write my IAM policy statements in either JSON or YAML and the tool should automatically handle either format.<br/><br/>Ideally this would be a distinct feature from the `--format` flag introduced in https://github.com/awslabs/aws-iam-generator/pull/13 which IMO should be refactored to influence the CloudFormation output format only.<br/>" ]]></description>
</item>

<item>
	<title>Create an operator that can detect scenes in video.</title>
	<link>https://github.com/awslabs/aws-media-insights-engine/issues/11</link>
	<description><![CDATA[This operator will be very useful to help determine different scenes in video.  Applications include searching for ads, credits, slates, scenes.  Another application is that applying ML to unique scenes would save processing time by running ML on still frames, rather than on video." ]]></description>
</item>

<item>
	<title>Add MediaTailor metrics to Monitor compartment</title>
	<link>https://github.com/awslabs/aws-media-services-application-mapper/issues/54</link>
	<description><![CDATA[End-user would like to see current metrics for beacon nofilter, beacon ad only, beacon jingles only, if possible.<br/>" ]]></description>
</item>

<item>
	<title>Add documentation for H/A configuration</title>
	<link>https://github.com/awslabs/aws-media-services-application-mapper/issues/9</link>
	<description><![CDATA[Add HA ]]></description>
</item>

<item>
	<title>Add documentation for MSAM REST API</title>
	<link>https://github.com/awslabs/aws-media-services-application-mapper/issues/8</link>
	<description><![CDATA[REST ]]></description>
</item>

<item>
	<title>Swagger UI demo</title>
	<link>https://github.com/awslabs/aws-serverless-java-container/issues/222</link>
	<description><![CDATA[* Implementations: Jersey / Spring / Spring Boot / Spark<br/><br/>## Scenario<br/>Add the ability to serve a `swagger-ui.html` to the sample applications as mentioned in #214 <br/><br/>## Expected behavior<br/>Navigating to `/ui/swagger-ui.html` should return the generated Swagger UI html page." ]]></description>
</item>

<item>
	<title>Dropwizard example?</title>
	<link>https://github.com/awslabs/aws-serverless-java-container/issues/128</link>
	<description><![CDATA[Can this framework support Dropwizard?  I have a REST server using dropwizard, JAX-RS, and hibernate and would like to port to Lambda.  If there are any examples of how to do this, please let me know.  Thanks" ]]></description>
</item>

<item>
	<title>Apache Camel route is supported?</title>
	<link>https://github.com/awslabs/aws-serverless-java-container/issues/58</link>
	<description><![CDATA[I was unable to run Apache Camel route in AWS Lambda. Do this container supports running Apache Camel route?" ]]></description>
</item>

<item>
	<title>Support for Jooby framework</title>
	<link>https://github.com/awslabs/aws-serverless-java-container/issues/46</link>
	<description><![CDATA[If it is convenient Support [Jooby ](http://jooby.org) framework?!" ]]></description>
</item>

<item>
	<title>Add support for Play framework</title>
	<link>https://github.com/awslabs/aws-serverless-java-container/issues/19</link>
	<description><![CDATA[Logging the feature request from our Twitter poll: https://twitter.com/sapessi/status/846816218422034432<br/><br/>Add support for the [Play Framework](https://www.playframework.com/)." ]]></description>
</item>

<item>
	<title>trouble with connecting to dynamodb through Java</title>
	<link>https://github.com/awslabs/dynamodb-janusgraph-storage-backend/issues/233</link>
	<description><![CDATA[Hi - I have the following Java code which I am trying to use to have Janusgraph connect to the cloud dynamodb (as opposed to the local test version).<br/><br/>import org.apache.commons.configuration.BaseConfiguration;<br/>import com.amazon.janusgraph.diskstorage.dynamodb.DynamoDBStoreManager;<br/>import org.janusgraph.core.JanusGraphFactory;<br/>import org.janusgraph.core.JanusGraph;<br/>.....<br/>BaseConfiguration conf = new BaseConfiguration();<br/>conf.setProperty(\"storage.backend\",\"com.amazon.janusgraph.diskstorage.dynamodb.DynamoDBStoreManager\");<br/>....JanusGraph graph = JanusGraphFactory.open(conf);<br/><br/>The error I'm getting when trying to run is:<br/>\"errorMessage\": \"Could not instantiate implementation: com.amazon.janusgraph.diskstorage.dynamodb.DynamoDBStoreManager\",<br/>....<br/>\"errorType\": \"java.lang.NoClassDefFoundError\",<br/><br/>Is this a bug or am I missing something? Thought importing com.amazon.janusgraph.diskstorage.dynamodb.DynamoDBStoreManager would be enough - I have dynamodb-janusgraph-storage-backend listed as a dependency in my pom.xml file so everything is compiling just fine.<br/><br/>I've found examples of how to use Gremlin with dynamodb/janusgraph but nothing about how to set things up purely in Java. An example would be greatly appreciated." ]]></description>
</item>

<item>
	<title>coio is not build in cargo.io migrate to tokyo the tls module</title>
	<link>https://github.com/awslabs/flowgger/issues/45</link>
	<description><![CDATA[to unlock https://github.com/awslabs/flowgger/issues/32 coio has to go<br/><br/>it's used in the TLS module as a scheduler and to control tcplistener and stream.<br/><br/>The package doesn't seem to have been touched for at least an year:<br/>https://github.com/zonyitoo/coio-rs<br/><br/>" ]]></description>
</item>

<item>
	<title>Enhance kafka commit</title>
	<link>https://github.com/awslabs/flowgger/issues/26</link>
	<description><![CDATA[Hello,<br/><br/>I think, it could be very useful to enhance \"Kafka output\" with a kind of timer option and associate it with the actual  ]]></description>
</item>

<item>
	<title>Question: netflow inputs?</title>
	<link>https://github.com/awslabs/flowgger/issues/14</link>
	<description><![CDATA[Hi, would netflow/ipfix be an input of interest? " ]]></description>
</item>

<item>
	<title>[question] any plans to be able to push directly to elasticsearch ?</title>
	<link>https://github.com/awslabs/flowgger/issues/11</link>
	<description><![CDATA[" ]]></description>
</item>

<item>
	<title>Metrics</title>
	<link>https://github.com/awslabs/flowgger/issues/1</link>
	<description><![CDATA[Awesome code, thanks a lot.<br/><br/>May you please consider to expose some metrics?<br/>Such as: uptime, number of active sessions, message received, sent, droped (charset or bad format).<br/>" ]]></description>
</item>

<item>
	<title>Keras-MXNet RNN CPU performance is slower</title>
	<link>https://github.com/awslabs/keras-apache-mxnet/issues/99</link>
	<description><![CDATA[Keras-MXNet is slower on CPU.<br/>See early benchmark results here - https://github.com/awslabs/keras-apache-mxnet/blob/master/benchmark/benchmark ]]></description>
</item>

<item>
	<title>Supporting MTCNN style model serving?</title>
	<link>https://github.com/awslabs/mxnet-model-server/issues/238</link>
	<description><![CDATA[Hi there, <br/><br/>    Great framework for serving mxnet based models!<br/><br/>    I wonder if there is any suggestions on supporting multi-stage models such as MTCNN, https://github.com/pangyupo/mxnet ]]></description>
</item>

<item>
	<title>Add heartbeat API to reference server</title>
	<link>https://github.com/awslabs/speke-reference-server/issues/13</link>
	<description><![CDATA[https://docs.aws.amazon.com/speke/latest/documentation/heartbeat.html<br/><br/>GET https://[server]/[stage]/heartbeat<br/><br/><br/>" ]]></description>
</item>

<item>
	<title>Lambda zip for keyserver not updated during stack update</title>
	<link>https://github.com/awslabs/speke-reference-server/issues/10</link>
	<description><![CDATA[Need to make CloudFormation aware that the keyserver zip has changed and requires an update. Right now CF doesn't know about a code change since only the zip contents change.<br/>" ]]></description>
</item>

<item>
	<title>ClientLambdaFunction</title>
	<link>https://github.com/awslabs/speke-reference-server/issues/1</link>
	<description><![CDATA[HI,<br/><br/>I downloaded the SPEKE reference implementation and setup the server using the template provided. I can't seem to find the ClientLambdaFunction to set the following parameter:<br/><br/>`CLIENT ]]></description>
</item>


</channel>
</rss>
